{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "ffd21041-30b0-4610-810a-7b52105cd9de",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Library for accessing operation system functionality - environment variables here\n",
    "import os\n",
    "# Library used to load environment variables\n",
    "from dotenv import load_dotenv\n",
    "# OpenAI library\n",
    "from openai import OpenAI\n",
    "# Library to manage tokens\n",
    "import tiktoken\n",
    "# DateTime library\n",
    "from datetime import datetime\n",
    "# Library to work with JSON data\n",
    "import json\n",
    "\n",
    "# Load environment variables from .env file\n",
    "load_dotenv()\n",
    "# Access OpenAI's API Key stored in the .env file which is in the root folder\n",
    "API_KEY = os.getenv('API_KEY')\n",
    "\n",
    "# Set default values \n",
    "DEFAULT_MODEL = 'gpt-4o'\n",
    "DEFAULT_TEMPERATURE = 0.9\n",
    "DEFAULT_MAX_TOKENS = 512\n",
    "DEFAULT_TOKEN_BUDGET = 4096\n",
    "\n",
    "# Class to manage chatbot conversations \n",
    "# Includes session management, token management, persona setting, session management & persistence to files\n",
    "class ChatManager():\n",
    "    def __init__(self, api_key=None, model=None, temperature=None,max_tokens=None, token_budget=None,history_filepath=None):\n",
    "        self.api_key = api_key if api_key else API_KEY\n",
    "        self.model = model if model else DEFAULT_MODEL\n",
    "        self.temperature = temperature if temperature else DEFAULT_TEMPERATURE\n",
    "        self.max_tokens = max_tokens if max_tokens else DEFAULT_MAX_TOKENS\n",
    "        self.token_budget = token_budget if token_budget else DEFAULT_TOKEN_BUDGET\n",
    "\n",
    "        # Initiatialize list to track multi-turn conversations - prompts and responses\n",
    "        self.messages = []\n",
    "        # Txt file to persist sessions at frequent checkpoints to ensure continuity\n",
    "        self.history_filepath = history_filepath if history_filepath else self.get_history_filename()\n",
    "        # Initialize OpenAI client\n",
    "        self.client = OpenAI(api_key=self.api_key)\n",
    "\n",
    "    \n",
    "    def get_history_filepath(self):\n",
    "        current_dt = datetime.now()\n",
    "        formatted_dt = current_dt.strftime('%Y-%m-%d %H:%M:%S')\n",
    "        filename = f\"chat_history_{formatted_dt}\"\n",
    "        return filename\n",
    "\n",
    "    # Function returns JSON messages from file\n",
    "    def load_json_from_file(self):\n",
    "      #  print(f'The history_filepath is {self.history_filepath}')\n",
    "        try:\n",
    "            with open(self.history_filepath, 'r') as file:\n",
    "                data = json.load(file)\n",
    "            return data \n",
    "        except FileNotFoundError:\n",
    "            print(f\"Error: The file '{self.history_filepath}' does not exist.\")\n",
    "        except json.JSONDecodeError:\n",
    "            print(f\"Error: The file '{self.history_filepath}' contains invalid JSON.\")\n",
    "        except Exception as e:\n",
    "            print(f\"An unexpected error occurred: {e}\")\n",
    "\n",
    "    # Function prepopulates the messages history list with JSON data from previous conversations \n",
    "    def load_conv_history(self):\n",
    "        json_data = self.load_json_from_file()\n",
    "        if json_data is not None:\n",
    "           # print(json_data)\n",
    "            self.messages = json_data\n",
    "            \n",
    "    # Function persists the messages history list to file         \n",
    "    def save_conv_history(self):\n",
    "        try:\n",
    "            with open(self.history_filepath,'w') as file:\n",
    "                json.dump(self.messages, file, indent=4)\n",
    "            #print(f'Successfully saved data to {self.history_filepath}')\n",
    "        except FileNotFoundError:\n",
    "            print(f'Error: The file {self.history_filepath} doesnt exist')\n",
    "        except IOError:\n",
    "            print(f'Error: Could not read file {self.history_filepath}')\n",
    "        except Exception as e:\n",
    "            print(f'An unexpected error occurred: {e}')\n",
    "\n",
    "    def count_tokens(self, text):\n",
    "        #Initiatize the tokenizer\n",
    "        tokenizer = tiktoken.encoding_for_model('gpt-4')\n",
    "        #Tokenize the input text\n",
    "        tokens = tokenizer.encode(text)\n",
    "        #return the number of tokens\n",
    "        return len(tokens)\n",
    "\n",
    "    def total_tokens_used(self):\n",
    "        total_tokens = 0\n",
    "        for row in self.messages:\n",
    "            total_tokens+=self.count_tokens(row['content'])\n",
    "        return total_tokens\n",
    "\n",
    "    def enforce_token_budget(self):\n",
    "        try:\n",
    "            while self.total_tokens_used() >= self.token_budget:\n",
    "                if len(self.messages) > 1:\n",
    "                    self.messages.pop(1)\n",
    "        except Exception as e:\n",
    "            print(f\"An unexpected error occurred: {e}\")\n",
    "\n",
    "    def chat_completion(self,prompt):\n",
    "        self.load_conv_history()\n",
    "        #print(f\"Total length of messages in conv history is {len(self.messages)}\")\n",
    "        self.messages.append({'role':'user','content':prompt})\n",
    "        self.enforce_token_budget()\n",
    "        #print(f\"Total tokens used so far is {self.total_tokens_used()}\")\n",
    "        response = self.client.chat.completions.create(seed=122, messages=self.messages,model=self.model, temperature=self.temperature, max_tokens = self.max_tokens)\n",
    "        self.messages.append({'role':'assistant','content':response.choices[0].message.content})\n",
    "        self.save_conv_history()\n",
    "        return response.choices[0].message.content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "4d4686f4-e864-44e3-922c-1572a401982f",
   "metadata": {},
   "outputs": [],
   "source": [
    "conv_manager = ChatManager(temperature = 1.0,history_filepath='conv_history.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "d72e3674-83e8-4a14-88f9-21c7a3506623",
   "metadata": {},
   "outputs": [],
   "source": [
    "response = conv_manager.chat_completion(prompt='Create a short funny tag line for Ugg shoe brand')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "a5ad57ab-e2ad-4eb8-b917-4b0ee3f5f7a3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\"Ugg: Because your feet deserve a vacation too!\"\n"
     ]
    }
   ],
   "source": [
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "cf4de197-50e2-4928-9500-6482e8c37d63",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "user and Create a short funny tag line for Ugg shoe brand\n",
      "assistant and \"Ugg: When your feet want a cozy bear hug!\"\n",
      "user and Create a short funny tag line for Ugg shoe brand\n",
      "assistant and \"Ugg: Because your feet deserve a vacation too!\"\n"
     ]
    }
   ],
   "source": [
    "for row in conv_manager.messages:\n",
    "    print(f\"{row['role']} and {row['content']}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2619907d-459d-40f4-99db-152a21656db9",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:base] *",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
